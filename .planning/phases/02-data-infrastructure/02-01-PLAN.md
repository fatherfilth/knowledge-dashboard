---
phase: 02-data-infrastructure
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - package.json
  - src/lib/github.ts
  - src/lib/content.ts
  - src/lib/schemas/article.ts
  - src/types/content.ts
  - scripts/verify-content.ts
autonomous: true

must_haves:
  truths:
    - "GitHub API client fetches all markdown files from fatherfilth/AI-Documentation-Library"
    - "Authenticated requests use GITHUB_TOKEN (5000 req/hr vs 60 unauthenticated)"
    - "All 6 category folders (models, tools, skills, repos, agents, projects) are accessible"
    - "Frontmatter is parsed by gray-matter and validated against Zod schema"
    - "Files in docs/_templates/ and docs/_index/ are excluded from content"
    - "Empty categories (only .gitkeep) return empty arrays without errors"
    - "Non-article files (README.md, .gitkeep) are filtered out"
  artifacts:
    - path: "src/lib/github.ts"
      provides: "Octokit client singleton and repository configuration"
      exports: ["octokit", "REPO_CONFIG"]
    - path: "src/lib/schemas/article.ts"
      provides: "Zod schema for article frontmatter with correct status enum"
      exports: ["ArticleFrontmatterSchema", "ArticleFrontmatter"]
    - path: "src/types/content.ts"
      provides: "Article type combining frontmatter + content + metadata"
      exports: ["Article", "Category"]
    - path: "src/lib/content.ts"
      provides: "Content fetching, parsing, and validation pipeline"
      exports: ["fetchCategoryArticles", "fetchAllArticles", "fetchCategories"]
    - path: "scripts/verify-content.ts"
      provides: "Verification script proving all data infrastructure works end-to-end"
  key_links:
    - from: "src/lib/content.ts"
      to: "src/lib/github.ts"
      via: "imports octokit and REPO_CONFIG"
      pattern: "import.*from.*github"
    - from: "src/lib/content.ts"
      to: "src/lib/schemas/article.ts"
      via: "validates parsed frontmatter against Zod schema"
      pattern: "ArticleFrontmatterSchema\\.safeParse"
    - from: "src/lib/content.ts"
      to: "gray-matter"
      via: "parses raw markdown into frontmatter + content"
      pattern: "matter\\("
    - from: "src/lib/github.ts"
      to: "process.env.GITHUB_TOKEN"
      via: "authenticates Octokit client"
      pattern: "auth.*process\\.env\\.GITHUB_TOKEN"
    - from: "src/types/content.ts"
      to: "src/lib/schemas/article.ts"
      via: "Article type extends Zod-inferred ArticleFrontmatter"
      pattern: "ArticleFrontmatter"
---

<objective>
Build the complete data infrastructure for fetching, parsing, and validating content from the GitHub-hosted AI Documentation Library.

Purpose: This is the foundation for all content display. Every downstream phase (routing, article reader, categories, search) depends on this data layer reliably delivering validated articles from the GitHub repository.

Output: Working content pipeline that fetches markdown from GitHub API, parses frontmatter with gray-matter, validates with Zod, and exports typed Article objects. Verified by a script that proves end-to-end functionality against the live repository.
</objective>

<execution_context>
@C:/Users/Karl/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Karl/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-infrastructure/02-RESEARCH.md
@.planning/phases/01-project-foundation/01-01-SUMMARY.md
@package.json
@src/app/layout.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install dependencies and create Zod schema with TypeScript types</name>
  <files>package.json, src/lib/schemas/article.ts, src/types/content.ts</files>
  <action>
    Install the three data infrastructure dependencies:
    ```
    npm install octokit gray-matter zod
    npm install -D @types/gray-matter
    ```

    Note: `octokit` is the unified package (not `@octokit/rest` which is deprecated in favor of the unified package). gray-matter may or may not have built-in types; install @types/gray-matter only if needed (check if gray-matter ships its own).

    Create `src/lib/schemas/article.ts`:
    - Define `ArticleFrontmatterSchema` using Zod
    - CRITICAL: The actual content repo uses these status values: "in-progress", "stable", "complete" (NOT "draft", "published", "archived" as research suggested). The schema MUST use `z.enum(["in-progress", "stable", "complete"])`.
    - Category enum: `z.enum(["models", "tools", "skills", "repos", "agents", "projects"])`
    - Fields from actual repo frontmatter:
      - `title`: z.string()
      - `status`: z.enum(["in-progress", "stable", "complete"])
      - `category`: z.enum(["models", "tools", "skills", "repos", "agents", "projects"])
      - `slug`: z.string()
      - `created`: z.coerce.date() — gray-matter parses bare YAML dates (2026-02-14) into Date objects, so use coerce to handle both Date objects and date strings
      - `updated`: z.coerce.date() — same reason as created
      - `author`: z.string()
      - `tags`: z.array(z.string()).default([]) — use default([]) so articles without tags don't fail validation
    - Export inferred type: `export type ArticleFrontmatter = z.infer<typeof ArticleFrontmatterSchema>`

    Create `src/types/content.ts`:
    - Import ArticleFrontmatter from schemas
    - Define `Article` type: ArticleFrontmatter + `content: string` (the markdown body) + `path: string` (GitHub file path for debugging)
    - Define `Category` type as the union: "models" | "tools" | "skills" | "repos" | "agents" | "projects"
    - Define `CATEGORIES` const array: ["models", "tools", "skills", "repos", "agents", "projects"] as const
  </action>
  <verify>
    Run `npx tsc --noEmit` to confirm no TypeScript errors. Check that `node_modules/octokit`, `node_modules/gray-matter`, and `node_modules/zod` exist.
  </verify>
  <done>
    All three packages installed. Zod schema matches actual repository frontmatter structure (status enum uses "in-progress"/"stable"/"complete", dates use z.coerce.date()). TypeScript types compile without errors. Article type combines frontmatter with content body and file path.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create GitHub API client and content fetching pipeline</name>
  <files>src/lib/github.ts, src/lib/content.ts</files>
  <action>
    Create `src/lib/github.ts`:
    - Import Octokit from "octokit"
    - Create singleton: `export const octokit = new Octokit({ auth: process.env.GITHUB_TOKEN })`
    - If GITHUB_TOKEN is undefined, Octokit still works (unauthenticated, 60 req/hr). Log a warning but don't throw — allows local dev without token for testing (builds will still work, just rate-limited).
    - Define and export `REPO_CONFIG` as const:
      ```
      owner: "fatherfilth"
      repo: "AI-Documentation-Library"
      basePath: "docs"
      excludePaths: ["docs/_templates", "docs/_index"]
      categories: ["models", "tools", "skills", "repos", "agents", "projects"] as const
      ```

    Create `src/lib/content.ts`:
    - Import octokit and REPO_CONFIG from ./github
    - Import matter from "gray-matter"
    - Import ArticleFrontmatterSchema from ./schemas/article
    - Import Article type from @/types/content

    Implement `fetchCategoryArticles(category: string): Promise<Article[]>`:
    1. Call `octokit.rest.repos.getContent()` for path `${REPO_CONFIG.basePath}/${category}`
    2. Handle response: if not Array, return [] (not a directory)
    3. Filter entries: keep only type === "file" AND name.endsWith(".md") AND name !== "README.md" AND name !== ".gitkeep"
    4. Also exclude any file whose path starts with any REPO_CONFIG.excludePaths entry
    5. For each remaining file, fetch its content via `octokit.rest.repos.getContent()` with the file's path
    6. Type-narrow: check `"content" in fileData` before accessing
    7. Decode: `Buffer.from(fileData.content, "base64").toString("utf-8")`
    8. Parse: `const { data: frontmatter, content } = matter(rawContent)`
    9. Validate: `const result = ArticleFrontmatterSchema.safeParse(frontmatter)`
    10. If validation fails: `console.warn()` with file path and error details, skip the file (continue)
    11. If validation succeeds: push to results array with `{ ...result.data, content: content.trim(), path: file.path }`
    12. Return the articles array

    Implement `fetchAllArticles(): Promise<Article[]>`:
    1. Use `Promise.all(REPO_CONFIG.categories.map(cat => fetchCategoryArticles(cat)))`
    2. Flatten with `.flat()`
    3. Return all articles

    Implement `fetchCategories(): Promise<{ name: string; count: number }[]>`:
    1. Fetch articles per category using fetchCategoryArticles for each
    2. Return array of `{ name, count }` objects (useful for Phase 5 category navigation)

    Error handling considerations:
    - If a category directory doesn't exist (404), catch the error and return [] for that category
    - If GitHub API returns a rate limit error, let it propagate (build should fail so user knows to add token)
    - Use try/catch around individual file fetches so one bad file doesn't kill the entire category
  </action>
  <verify>
    Run `npx tsc --noEmit` to confirm no TypeScript errors in the new files. Verify imports resolve correctly.
  </verify>
  <done>
    GitHub client authenticates with GITHUB_TOKEN. Content pipeline fetches directory listings, filters to .md files only, excludes .gitkeep/README.md/templates/index directories, decodes base64 content, parses frontmatter with gray-matter, validates with Zod safeParse, and returns typed Article arrays. Errors on individual files are logged and skipped. Empty categories return empty arrays.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create verification script and prove end-to-end data pipeline works</name>
  <files>scripts/verify-content.ts</files>
  <action>
    Create `scripts/verify-content.ts` — a standalone script that exercises the full data pipeline against the live GitHub API and proves all requirements are met.

    The script must:
    1. Check GITHUB_TOKEN is set (warn if not, proceed anyway)
    2. Call fetchAllArticles() and report total article count
    3. Call fetchCategoryArticles() for EACH of the 6 categories individually and report per-category counts
    4. Verify all 6 categories are accessible (even empty ones return [] without error)
    5. For each article: confirm title, status, category, slug, tags are present and correctly typed
    6. Log a summary table showing: category | article count | sample titles
    7. Confirm docs/_templates/ and docs/_index/ are NOT in any article paths
    8. Report total API calls made and whether authenticated

    Run the script with:
    ```
    npx tsx scripts/verify-content.ts
    ```

    Note: tsx is a dev dependency of Next.js (ships with it) OR install it: `npm install -D tsx` if not available. If tsx is not available, use `node --import tsx scripts/verify-content.ts` or add a package.json script.

    Add to package.json scripts: `"verify-content": "tsx scripts/verify-content.ts"`

    After creating the script, run it. The output should show:
    - All 6 categories fetched successfully
    - Articles found in at least tools, skills, agents, projects categories
    - Zero articles from _templates or _index
    - All articles have valid frontmatter per Zod schema
    - Status values are "in-progress", "stable", or "complete" (not other values)

    If the script fails due to missing GITHUB_TOKEN in .env.local, update .env.local to uncomment the token line and provide instructions. The user should have a GitHub token set up (from Phase 1, it's already configured in Vercel). For local development, the user needs to set it in .env.local.

    IMPORTANT: The script must load .env.local before running. Either use dotenv or add a note that it should be run with the env var set. Since this is a Next.js project, use `@next/env` to load env or install dotenv as a dev dependency:
    ```
    npm install -D dotenv
    ```
    Then at the top of the script: `import "dotenv/config"` (this loads .env.local automatically with dotenv).

    Actually, simpler approach: use `dotenv` package with `{ path: ".env.local" }`:
    ```typescript
    import { config } from "dotenv";
    config({ path: ".env.local" });
    ```
  </action>
  <verify>
    Run `npm run verify-content` (or `npx tsx scripts/verify-content.ts`). Output shows:
    - "Authenticated: yes" (or "no" with warning)
    - Per-category article counts (tools: ~7, skills: ~5, agents: ~3, projects: ~2, models: 0, repos: 0)
    - Total articles: should be ~15-17 based on current repo state
    - "All articles validated successfully" (or lists any validation failures)
    - "Excluded paths verified: no _templates or _index articles"
    - Script exits with code 0

    Also run `npm run build` to ensure the new dependencies and code don't break the existing Next.js build.
  </verify>
  <done>
    Verification script proves end-to-end: GitHub API fetches all articles from all 6 categories, frontmatter validates against Zod schema, excluded directories are filtered, empty categories handled gracefully. Build still passes. The data infrastructure is ready for Phase 3 (routing and static page generation).
  </done>
</task>

</tasks>

<verification>
Phase 2 success criteria verification:
1. "GitHub API client successfully fetches all markdown files" — verify-content script reports article counts per category
2. "Authenticated requests prevent rate limiting" — verify-content script confirms authenticated mode
3. "All 6 category folders accessible" — verify-content script fetches all 6, including empty ones
4. "Frontmatter parsed and validated against Zod schema" — verify-content script reports zero validation failures on valid content
5. "Files in docs/_templates/ and docs/_index/ excluded" — verify-content script confirms no excluded paths in results
</verification>

<success_criteria>
- `npm run verify-content` exits 0 with all categories fetched and articles validated
- `npm run build` completes without errors
- `npx tsc --noEmit` passes with no type errors
- At least 15 articles fetched and validated across the 6 categories
- Zero articles from docs/_templates/ or docs/_index/ in results
- All article status values are one of: "in-progress", "stable", "complete"
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-infrastructure/02-01-SUMMARY.md`
</output>
